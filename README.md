# Papers Read During the 2024 Year

## This does not count papers read during regularly scheduled reading groups (i.e., with the Northeastern Cosmology Department and with the [GammaTau AI Reading Group](https://github.com/GammaTauAI/WeeklyReadingsArchive) ). These are my "for fun" papers.

| Paper | Description | 
|-------| ------------| 
| [PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Network](https://arxiv.org/abs/2307.11833) | Transformers for Physics Informed Neural Networks |
| [Physics-Informed Neural Networks as Solvers for the Time-Dependent Schrödinger Equation](https://arxiv.org/pdf/2210.12522.pdf) | PINNs for the Schrödinger equation. Provides insight on how to deal with complex valued functions |
| [Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361.pdf) | Transformer Scaling Laws |
| [NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with Error Approximations](https://arxiv.org/pdf/2107.09443.pdf) | Provides good background on PINNs and NeuralPDE.jl |
| [Large-scale Neural Solvers for Partial Differential Equations](https://arxiv.org/pdf/2009.03730.pdf) | Mixture of Experts for PINNs |
| [Numerical Calabi-Yau metrics from holomorphic networks](https://arxiv.org/pdf/2012.04797.pdf) | PINNs (holomorphic networks) for metrics |
| [Physics-Informed Machine Learning: A Survey on Problems, Methods and Applications](https://arxiv.org/pdf/2211.08064.pdf) | GOATed Survey |
| [WHEN AND WHY PINNS FAIL TO TRAIN: A NEURAL TANGENT KERNEL PERSPECTIVE](https://arxiv.org/pdf/2007.14527.pdf) | NTK Method. Such a sick paper!!! Very nice. |
| [Rotational and reflectional equivariant convolutional neural network for data-limited applications: Multiphase flow demonstration](https://pubs.aip.org/aip/pof/article/33/10/103323/1064980/Rotational-and-reflectional-equivariant) | PINNs with equivariance |
| [Social Contract AI: Aligning AI Assistants with Implicit Group Norms](https://arxiv.org/pdf/2310.17769.pdf) | Exploring AI Assistants |
| [Riemannian Residual Neural Networks](https://arxiv.org/pdf/2310.10013.pdf) | Awesome sauce manifold learning paper. I have done similar work! |
| [How to Find Variable Active Galactic Nuclei with Machine Learning](https://arxiv.org/pdf/1908.07542.pdf) | Title |
| [Towards Automated Circuit Discovery for Mechanistic Interpretability](https://arxiv.org/pdf/2304.14997.pdf) | Finds subgraphs corresponding to moreorless the same desired behaviors in the original transformers, i.e., circuits that do a task |
| [The Lie Derivative for Measuring Learned Equivariance](https://arxiv.org/pdf/2210.02984.pdf) | Counter intuitive results on measured equivariance in non equivariant networks |
| [THE N5K CHALLENGE: NON-LIMBER INTEGRATION FOR LSST COSMOLOGY](https://arxiv.org/pdf/2212.04291.pdf) | Numeric Integration Methods for 2x3pt correlation functions |
| [Modeling halo and central galaxy orientations on the SO(3) manifold with score-based generative models](https://arxiv.org/pdf/2212.05592.pdf) | Easy read, I read it because Francois is a coauthor and I have had the pleasure of meeting him, and I happened to come across it |
| [Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks](https://arxiv.org/pdf/2401.17263.pdf) | Cool paper that achieves SOTA on preventing Jailbreaking attacks |
| [The SNR of a Transit](https://arxiv.org/pdf/2305.06790.pdf) | Trying to learn more about cool worlds lab |
| [A MATHEMATICAL PERSPECTIVE ON TRANSFORMERS](https://arxiv.org/pdf/2312.10794.pdf) | Insane Maths, not really Interpretability, can almost be though of as a physics for transformers |
| [A Phase Transition between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention](https://arxiv.org/pdf/2402.03902.pdf) | Stat Mechs, similar |
| [The clock and the pizza: Two stories in mechanistic explanation of neural networks](https://arxiv.org/pdf/2306.17844.pdf) | Pizza |
